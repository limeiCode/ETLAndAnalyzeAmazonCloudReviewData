{
  "paragraphs": [
    {
      "title": "",
      "text": "",
      "user": "",
      "dateUpdated": "2020-01-09 19:07:34.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [],
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20200109-185045_1075320060",
      "dateCreated": "2020-01-09 18:50:45.000",
      "dateStarted": "2020-01-09 19:03:31.857",
      "dateFinished": "2020-01-09 19:07:25.065",
      "status": "ABORT",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\nfrom pyspark import SparkFiles\nurl \u003d \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Software_v1_00.tsv.gz\"\nspark.sparkContext.addFile(url)\nSoftware_df \u003d spark.read.option(\u0027header\u0027, \u0027true\u0027).csv(SparkFiles.get(\"amazon_reviews_us_Software_v1_00.tsv.gz\"), sep\u003d\"\\t\", header\u003dTrue, inferSchema\u003dTrue) \n",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:08.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20200109-140301_791171392",
      "dateCreated": "2020-01-09 14:03:01.000",
      "dateStarted": "2020-01-10 22:21:00.930",
      "dateFinished": "2020-01-10 22:21:08.865",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\nSoftware_df.show(1)  # show one record to check data type of each field",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:09.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|        review_date|\n+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n|         US|   42605767|R3EFW2STIYIY0I|B00MUTIDKI|     248732228|McAfee 2015 Inter...|        Software|          1|            2|          2|   N|                Y|I was very disapp...|I was very disapp...|2015-08-31 00:00:00|\n+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\nonly showing top 1 row\n\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-155939_1410448768",
      "dateCreated": "2020-01-10 15:59:39.000",
      "dateStarted": "2020-01-10 22:21:08.867",
      "dateFinished": "2020-01-10 22:21:09.084",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\nSoftware_df.count()",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:09.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "341931",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-194809_364706983",
      "dateCreated": "2020-01-10 19:48:09.000",
      "dateStarted": "2020-01-10 22:21:09.086",
      "dateFinished": "2020-01-10 22:21:09.301",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\nlen(Software_df.columns)",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:09.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "15",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-190624_413761074",
      "dateCreated": "2020-01-10 19:06:24.000",
      "dateStarted": "2020-01-10 22:21:09.302",
      "dateFinished": "2020-01-10 22:21:09.419",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\nSoftware_df.columns",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:09.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "[\u0027marketplace\u0027,\n \u0027customer_id\u0027,\n \u0027review_id\u0027,\n \u0027product_id\u0027,\n \u0027product_parent\u0027,\n \u0027product_title\u0027,\n \u0027product_category\u0027,\n \u0027star_rating\u0027,\n \u0027helpful_votes\u0027,\n \u0027total_votes\u0027,\n \u0027vine\u0027,\n \u0027verified_purchase\u0027,\n \u0027review_headline\u0027,\n \u0027review_body\u0027,\n \u0027review_date\u0027]",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-194733_1512374286",
      "dateCreated": "2020-01-10 19:47:33.000",
      "dateStarted": "2020-01-10 22:21:09.420",
      "dateFinished": "2020-01-10 22:21:09.538",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "",
      "user": "",
      "dateUpdated": "2020-01-10 19:48:34.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [],
        "editorSetting": {}
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-194753_833116959",
      "dateCreated": "2020-01-10 19:47:53.000",
      "dateStarted": "2020-01-10 23:05:51.000",
      "dateFinished": "2020-01-10 23:05:51.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\nSoftware_df.printSchema()",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:09.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "root\n |-- marketplace: string (nullable \u003d true)\n |-- customer_id: integer (nullable \u003d true)\n |-- review_id: string (nullable \u003d true)\n |-- product_id: string (nullable \u003d true)\n |-- product_parent: integer (nullable \u003d true)\n |-- product_title: string (nullable \u003d true)\n |-- product_category: string (nullable \u003d true)\n |-- star_rating: integer (nullable \u003d true)\n |-- helpful_votes: integer (nullable \u003d true)\n |-- total_votes: integer (nullable \u003d true)\n |-- vine: string (nullable \u003d true)\n |-- verified_purchase: string (nullable \u003d true)\n |-- review_headline: string (nullable \u003d true)\n |-- review_body: string (nullable \u003d true)\n |-- review_date: timestamp (nullable \u003d true)\n\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-161431_635471303",
      "dateCreated": "2020-01-10 16:14:31.000",
      "dateStarted": "2020-01-10 22:21:09.539",
      "dateFinished": "2020-01-10 22:21:09.656",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\nSoftware_df.cache()",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:09.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "DataFrame[marketplace: string, customer_id: int, review_id: string, product_id: string, product_parent: int, product_title: string, product_category: string, star_rating: int, helpful_votes: int, total_votes: int, vine: string, verified_purchase: string, review_headline: string, review_body: string, review_date: timestamp]",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20200109-191140_440172227",
      "dateCreated": "2020-01-09 19:11:40.000",
      "dateStarted": "2020-01-10 22:21:09.658",
      "dateFinished": "2020-01-10 22:21:09.772",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\nSoftware_df.select([\"vine\",\"verified_purchase\"]).describe().show()",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:14.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "tableHide": false,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "+-------+------+-----------------+\n|summary|  vine|verified_purchase|\n+-------+------+-----------------+\n|  count|341931|           341931|\n|   mean|  null|             null|\n| stddev|  null|             null|\n|    min|     N|                N|\n|    max|     Y|                Y|\n+-------+------+-----------------+\n\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-191125_202021226",
      "dateCreated": "2020-01-10 19:11:25.000",
      "dateStarted": "2020-01-10 22:21:09.774",
      "dateFinished": "2020-01-10 22:21:14.402",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\nSoftware_df.select(\"verified_purchase\").filter(\"verified_purchase\u003d\u003dnull\").count()\nSoftware_df.select(\"verified_purchase\").filter(\"verified_purchase\u003d\u003d\u0027Y\u0027\").count()",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:14.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "195647",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-203140_1522946727",
      "dateCreated": "2020-01-10 20:31:40.000",
      "dateStarted": "2020-01-10 22:21:14.404",
      "dateFinished": "2020-01-10 22:21:14.719",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n# change \u0027vine\u0027 TEXT \"Y\"/\"N\" to BOOLEAN \"True\"/\"False\": 1) define new schema for \u0027vine\u0027 as new datatype Boolean + ReExtract \n# 2) add a new column \u0027vinenew\u0027 as BOOLEAN + assign values based on \u0027vine\u0027 \n# 1)\nfrom pyspark.sql.types import StructField, StringType, IntegerType, StructType,BooleanType\n#newschema\u003d[StructField(\"marketplace\",StringType(),True),StructField(\"customer_id\",IntegerType,True),....,StructField(\"vine\",BooleanType, True)]\n#marketplace: string, customer_id: int, review_id: string, product_id: string, product_parent: int, product_title: string, product_category: string, star_rating: int, \n#helpful_votes: int, total_votes: int, vine: string, verified_purchase: string, review_headline: string, review_body: string, review_date: timestamp\n#Software_df \u003d spark.read.option(\u0027header\u0027, \u0027true\u0027).csv(SparkFiles.get(\"amazon_reviews_us_Software_v1_00.tsv.gz\"), sep\u003d\"\\t\", header\u003dTrue, schema\u003dnewschema) \n# 2)",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:14.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-210556_713232104",
      "dateCreated": "2020-01-10 21:05:56.000",
      "dateStarted": "2020-01-10 22:21:14.721",
      "dateFinished": "2020-01-10 22:21:14.834",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\nproducts_df \u003d Software_df.select([\"product_id\", \"product_title\"]).drop_duplicates()\ncustomers_df \u003d Software_df.groupby(\"customer_id\").agg({\"customer_id\": \"count\"}).withColumnRenamed(\"count(customer_id)\", \"customer_count\")\nfrom pyspark.sql.functions import to_date\nreviews_df \u003d Software_df.select([\"review_id\", \"customer_id\", \"product_id\", \"product_parent\", to_date(\"review_date\").alias(\"review_date\")])\nvine_df \u003d Software_df.select([\"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", \"vine\"])\nvine_df.show(10)\n",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:15.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "+--------------+-----------+-------------+-----------+----+\n|     review_id|star_rating|helpful_votes|total_votes|vine|\n+--------------+-----------+-------------+-----------+----+\n|R3EFW2STIYIY0I|          1|            2|          2|   N|\n|R12NR0R5A9F7FT|          5|            0|          0|   N|\n|R1LSH74R9XAP59|          2|            0|          1|   N|\n|R1QXUNTF76K7L6|          2|            0|          0|   N|\n|R2F7DR75PS8NKT|          5|            0|          0|   N|\n|R2C1DJSCC8UFS6|          3|            0|          0|   N|\n|R1AXGS1W4YFXMX|          1|            0|          2|   N|\n|R1XU1B93402SYJ|          1|            1|          1|   N|\n|R2U432NB3OPVR0|          5|            0|          0|   N|\n|R3R6FIMIOQ5SP9|          5|            0|          0|   N|\n+--------------+-----------+-------------+-----------+----+\nonly showing top 10 rows\n\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-193559_1318240519",
      "dateCreated": "2020-01-10 19:35:59.000",
      "dateStarted": "2020-01-10 22:21:14.836",
      "dateFinished": "2020-01-10 22:21:15.152",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n#coffee_ratings_df \u003d shop_df.groupby(\"coffee_shop_name\").agg({\"num_rating\": \"avg\", \"coffee_shop_name\":\"count\"})\n#from pyspark.sql.functions import desc\n#coffee_ratings_df \u003d coffee_ratings_df.withColumnRenamed(\"count(coffee_shop_name)\", \"total_ratings\").withColumnRenamed(\"avg(num_rating)\", \"avg_rating\")\n#coffee_ratings_df.orderBy(desc(\"avg_rating\")).show()\n#from pyspark.sql.functions import regexp_extract\n#review_text \u003d \"11/25/2016 1 chec...\"\n#review_df \u003d review_df.withColumn(\"date\", regexp_extract(\"review_text\", \"\\d+/\\d+/\\d+\", 0))\\\n#      .withColumn(\"review_text\", regexp_extract(\"review_text\", \"\\d+/\\d+/\\d+(?:\\s)(.*)\", 1))\\\n#      .select([\"date\", \"review_text\"]).dropna()\n",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:15.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-195810_371501675",
      "dateCreated": "2020-01-10 19:58:10.000",
      "dateStarted": "2020-01-10 22:21:15.153",
      "dateFinished": "2020-01-10 22:21:15.267",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n#mode \u003d \"append\"\n#jdbc_url\u003d\"jdbc:postgresql://\u003c\"endpoint\"\u003e:5432/my_data_class_db\"\n#config \u003d {\"user\":\"root\", \"password\": \"\u003cpassword\u003e\", \"driver\":\"org.postgresql.Driver\"}\n",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:15.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-215347_1147463243",
      "dateCreated": "2020-01-10 21:53:47.000",
      "dateStarted": "2020-01-10 22:21:15.268",
      "dateFinished": "2020-01-10 22:21:15.382",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\nmode \u003d \"append\"\njdbc_url\u003d\"jdbc:postgresql://postgresqlforetlsoftwareandvideodvdreview.cgjfasmmonou.us-east-2.rds.amazonaws.com:5432/PostgreSQLForETLSoftwareAndVideoDVDReview\"\nconfig \u003d {\"user\":\"root\", \"password\": \"lmpostgre1!\", \"driver\":\"org.postgresql.Driver\"}\n#Endpoint: [ postgresqlforetlsoftwareandvideodvdreview.cgjfasmmonou.us-east-2.rds.amazonaws.com ]\n#Port:         [ 5432 ]\n#DB instance identifier:  [ PostgreSQLForETLSoftwareAndVideoDVDReview ]\n#Master username:        [ root ]\n#Master password:         [ lmpostgre1! ]  ",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:15.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-215349_529543443",
      "dateCreated": "2020-01-10 21:53:49.000",
      "dateStarted": "2020-01-10 22:21:15.383",
      "dateFinished": "2020-01-10 22:21:15.497",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\nproducts_df.write.jdbc(url\u003djdbc_url, table\u003d\u0027products\u0027, mode\u003dmode, properties\u003dconfig)",
      "user": "",
      "dateUpdated": "2020-01-10 22:59:57.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "data": "\u001b[0;31m\u001b[0m\n\u001b[0;31mPy4JJavaError\u001b[0mTraceback (most recent call last)\n\u001b[0;32m\u003cipython-input-120-bc543bab7717\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mproducts_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;34m\u0027products\u0027\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\n\u001b[0;32m/usr/zepl/spark-2.2/python/lib/pyspark.zip/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0mjprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 820\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m/usr/zepl/spark-2.2/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value \u003d get_return_value(\n\u001b[0;32m-\u003e 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m/usr/zepl/spark-2.2/python/lib/pyspark.zip/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m/usr/zepl/spark-2.2/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n\n\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o596.jdbc.\n: org.postgresql.util.PSQLException: FATAL: database \"PostgreSQLForETLSoftwareAndVideoDVDReview\" does not exist\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2497)\n\tat org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2618)\n\tat org.postgresql.core.v3.QueryExecutorImpl.\u003cinit\u003e(QueryExecutorImpl.java:135)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:250)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)\n\tat org.postgresql.jdbc.PgConnection.\u003cinit\u003e(PgConnection.java:195)\n\tat org.postgresql.Driver.makeConnection(Driver.java:458)\n\tat org.postgresql.Driver.connect(Driver.java:260)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$createConnectionFactory$1.apply(JdbcUtils.scala:61)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$createConnectionFactory$1.apply(JdbcUtils.scala:52)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:63)\n\tat org.apache.spark.sql.execution.datasources.DataSource.write(DataSource.scala:469)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:50)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:138)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:135)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:116)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:92)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:92)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:609)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:233)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:460)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-221848_1223005753",
      "dateCreated": "2020-01-10 22:18:48.000",
      "dateStarted": "2020-01-10 22:59:56.785",
      "dateFinished": "2020-01-10 22:59:57.456",
      "status": "ERROR",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n#products_df.write.jdbc(url\u003djdbc_url, table\u003d\u0027products\u0027, mode\u003dmode, properties\u003dconfig)\n#customers_df.write.jdbc(url\u003djdbc_url, table\u003d\u0027customers\u0027, mode\u003dmode, properties\u003dconfig)\n#reviews_df.write.jdbc(url\u003djdbc_url, table\u003d\u0027reviews\u0027, mode\u003dmode, properties\u003dconfig)\n#vine_df.write.jdbc(url\u003djdbc_url, table\u003d\u0027vine\u0027, mode\u003dmode, properties\u003dconfig)",
      "user": "",
      "dateUpdated": "2020-01-10 22:21:16.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20200109-004353_450034940",
      "dateCreated": "2020-01-09 00:43:53.000",
      "dateStarted": "2020-01-10 22:21:16.120",
      "dateFinished": "2020-01-10 22:21:16.233",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\n#Anslyzing vine table \n#vine_df \u003d Software_df.select([\"star_rating\", \"helpful_votes\", \"total_votes\", \"vine\", \"verified_purchase\"])\nvine_filtertotalvotes_df \u003d vine_df.filter(vine_df[\"total_votes\"] \u003e\u003d 20)\nvine_filtertotalvoteshelpfulvotes_df \u003d vine_filtertotalvotes_df.filter(vine_filtertotalvotes_df[\"helpful_votes\"]/vine_filtertotalvotes_df[\"total_votes\"] \u003e\u003d 0.5)\n",
      "user": "",
      "dateUpdated": "2020-01-10 22:49:10.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-224402_872381009",
      "dateCreated": "2020-01-10 22:44:02.000",
      "dateStarted": "2020-01-10 22:49:10.593",
      "dateFinished": "2020-01-10 22:49:10.707",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\nfrom pyspark.sql.functions import col, avg\npaid_df \u003d vine_filtertotalvoteshelpfulvotes_df.filter(vine_filtertotalvoteshelpfulvotes_df[\u0027vine\u0027]\u003d\u003d \u0027Y\u0027)\nunpaid_df \u003d vine_filtertotalvoteshelpfulvotes_df.filter(vine_filtertotalvoteshelpfulvotes_df[\u0027vine\u0027]\u003d\u003d \u0027N\u0027)\n\npaid_df.describe().show()\nunpaid_df.describe().show()",
      "user": "",
      "dateUpdated": "2020-01-10 22:50:26.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "+-------+--------------+------------------+------------------+------------------+----+\n|summary|     review_id|       star_rating|     helpful_votes|       total_votes|vine|\n+-------+--------------+------------------+------------------+------------------+----+\n|  count|           248|               248|               248|               248| 248|\n|   mean|          null|3.7943548387096775| 77.65725806451613| 81.91129032258064|null|\n| stddev|          null| 1.304790452368455|142.24734497903623|145.08341937129128|null|\n|    min|R12EV95D2T56HA|                 1|                15|                20|   Y|\n|    max| RZHYW4NFNGNWB|                 5|              1231|              1247|   Y|\n+-------+--------------+------------------+------------------+------------------+----+\n\n\n",
            "type": "TEXT"
          },
          {
            "data": "+-------+--------------+------------------+-----------------+-----------------+-----+\n|summary|     review_id|       star_rating|    helpful_votes|      total_votes| vine|\n+-------+--------------+------------------+-----------------+-----------------+-----+\n|  count|         17514|             17514|            17514|            17514|17514|\n|   mean|          null|2.8756423432682428|46.32185680027407|51.29542080621217| null|\n| stddev|          null|1.6981277376160198|68.69833838338252|72.36000784694947| null|\n|    min|R1002I943QCT20|                 1|               10|               20|    N|\n|    max| RZZVNZ1KUO6TY|                 5|             2243|             2394|    N|\n+-------+--------------+------------------+-----------------+-----------------+-----+\n\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-225008_1989106232",
      "dateCreated": "2020-01-10 22:50:08.000",
      "dateStarted": "2020-01-10 22:50:25.059",
      "dateFinished": "2020-01-10 22:50:26.327",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\npaid_five_star_number \u003d paid_df[paid_df[\u0027star_rating\u0027]\u003d\u003d 5].count()\npaid_number \u003d paid_df.count()\npercentage_five_star_vine \u003d float(paid_five_star_number) / float(paid_number)\nprint(\"paid_number\",paid_number)\nprint(\"paid_five_star_number\",paid_five_star_number)\nprint(\"percentage_five_star_vine\",percentage_five_star_vine)",
      "user": "",
      "dateUpdated": "2020-01-10 23:05:19.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "(\u0027paid_number\u0027, 248)\n(\u0027paid_five_star_number\u0027, 102)\n(\u0027percentage_five_star_vine\u0027, 0.4112903225806452)\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-225118_410601049",
      "dateCreated": "2020-01-10 22:51:18.000",
      "dateStarted": "2020-01-10 23:05:18.934",
      "dateFinished": "2020-01-10 23:05:19.249",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "%pyspark\nunpaid_five_star_number \u003d unpaid_df[unpaid_df[\u0027star_rating\u0027]\u003d\u003d 5].count()\nunpaid_number \u003d unpaid_df.count()\npercentage_five_star_non_vine \u003d float(unpaid_five_star_number) / float(unpaid_number)\nprint(\"unpaid_number\",unpaid_number)\nprint(\"unpaid_five_star_number\",unpaid_five_star_number)\nprint(\"unpaid_five_star_number/unpaid_number\",float(unpaid_five_star_number) / float(unpaid_number))\n",
      "user": "",
      "dateUpdated": "2020-01-10 23:04:44.000",
      "config": {
        "selectedInterpreter": {
          "name": "spark.pyspark",
          "profile": "pyspark",
          "isCustom": false,
          "editorLanguage": "python",
          "className": "org.apache.zeppelin.spark.PySparkInterpreter",
          "isDefault": false
        },
        "colWidth": 12.0,
        "results": [
          {}
        ],
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "data": "(\u0027unpaid_number:\u0027, 17514)\n(\u0027unpaid_five_star_number:\u0027, 5154)\n(\u0027unpaid_five_star_number/unpaid_number:\u0027, 0.29427886262418634)\n",
            "type": "TEXT"
          }
        ]
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-221808_265835090",
      "dateCreated": "2020-01-10 22:18:08.000",
      "dateStarted": "2020-01-10 23:04:32.682",
      "dateFinished": "2020-01-10 23:04:32.997",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    },
    {
      "title": "",
      "text": "",
      "user": "",
      "dateUpdated": "2020-01-10 22:52:29.000",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "",
      "id": "20200110-225229_399373269",
      "dateCreated": "2020-01-10 22:52:29.000",
      "dateStarted": "2020-01-10 23:05:51.000",
      "dateFinished": "2020-01-10 23:05:51.000",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 0
    }
  ],
  "name": "HW22",
  "id": "73d795bc52ea489e8a99ac08c86ba7bd",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {},
  "info": {}
}